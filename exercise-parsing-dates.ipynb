{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/parsing-dates).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Parsing dates** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex3 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:22:50.786887Z","iopub.execute_input":"2023-03-31T23:22:50.787408Z","iopub.status.idle":"2023-03-31T23:22:51.742087Z","shell.execute_reply.started":"2023-03-31T23:22:50.787362Z","shell.execute_reply":"2023-03-31T23:22:51.740605Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries and dataset we'll be using. We'll be working with a dataset containing information on earthquakes that occured between 1965 and 2016.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport datetime\n\n# read in our data\nearthquakes = pd.read_csv(\"../input/earthquake-database/database.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:22:55.845898Z","iopub.execute_input":"2023-03-31T23:22:55.846516Z","iopub.status.idle":"2023-03-31T23:22:55.953903Z","shell.execute_reply.started":"2023-03-31T23:22:55.846455Z","shell.execute_reply":"2023-03-31T23:22:55.952479Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# 1) Check the data type of our date column\n\nYou'll be working with the \"Date\" column from the `earthquakes` dataframe.  Investigate this column now: does it look like it contains dates?  What is the dtype of the column?","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here!\n","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.249334Z","iopub.execute_input":"2023-03-30T07:20:38.249735Z","iopub.status.idle":"2023-03-30T07:20:38.254436Z","shell.execute_reply.started":"2023-03-30T07:20:38.249699Z","shell.execute_reply":"2023-03-30T07:20:38.253174Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Once you have answered the question above, run the code cell below to get credit for your work.","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq1.check()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:22:59.658759Z","iopub.execute_input":"2023-03-31T23:22:59.660326Z","iopub.status.idle":"2023-03-31T23:22:59.672943Z","shell.execute_reply.started":"2023-03-31T23:22:59.660254Z","shell.execute_reply":"2023-03-31T23:22:59.671657Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"1_CheckDtype\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct: \n\nThe \"Date\" column in the `earthquakes` DataFrame does have dates.  The dtype is \"object\".","text/markdown":"<span style=\"color:#33cc33\">Correct:</span> \n\nThe \"Date\" column in the `earthquakes` DataFrame does have dates.  The dtype is \"object\"."},"metadata":{}}]},{"cell_type":"code","source":"# Line below will give you a hint\nq1.hint()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:23:02.184651Z","iopub.execute_input":"2023-03-31T23:23:02.185162Z","iopub.status.idle":"2023-03-31T23:23:02.195471Z","shell.execute_reply.started":"2023-03-31T23:23:02.185119Z","shell.execute_reply":"2023-03-31T23:23:02.194061Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 4, \"questionId\": \"1_CheckDtype\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Use `earthquakes['Date'].head()` to check that the column contains dates and verify that it has dtype \"object\".  You can also use `earthquakes['Date'].dtype` to verify the dtype.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Use `earthquakes['Date'].head()` to check that the column contains dates and verify that it has dtype \"object\".  You can also use `earthquakes['Date'].dtype` to verify the dtype."},"metadata":{}}]},{"cell_type":"markdown","source":"# 2) Convert our date columns to datetime\n\nMost of the entries in the \"Date\" column follow the same format: \"month/day/four-digit year\".  However, the entry at index 3378 follows a completely different pattern.  Run the code cell below to see this.","metadata":{}},{"cell_type":"code","source":"earthquakes[3378:3383]","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.282205Z","iopub.execute_input":"2023-03-30T07:20:38.282687Z","iopub.status.idle":"2023-03-30T07:20:38.326769Z","shell.execute_reply.started":"2023-03-30T07:20:38.282616Z","shell.execute_reply":"2023-03-30T07:20:38.325685Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                          Date                      Time  Latitude  Longitude  \\\n3378  1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017    124.075   \n3379                02/23/1975                  03:53:36   -21.727    -71.356   \n3380                02/23/1975                  07:34:11   -10.879    166.667   \n3381                02/25/1975                  05:20:05    -7.388    149.798   \n3382                02/26/1975                  04:48:55    85.047     97.969   \n\n            Type  Depth  Depth Error  Depth Seismic Stations  Magnitude  \\\n3378  Earthquake  623.0          NaN                     NaN        5.6   \n3379  Earthquake   33.0          NaN                     NaN        5.6   \n3380  Earthquake   33.0          NaN                     NaN        5.5   \n3381  Earthquake   33.0          NaN                     NaN        5.5   \n3382  Earthquake   33.0          NaN                     NaN        5.6   \n\n     Magnitude Type  ...  Magnitude Seismic Stations  Azimuthal Gap  \\\n3378             MB  ...                         NaN            NaN   \n3379             MB  ...                         NaN            NaN   \n3380             MS  ...                         NaN            NaN   \n3381             MB  ...                         NaN            NaN   \n3382             MS  ...                         NaN            NaN   \n\n      Horizontal Distance  Horizontal Error  Root Mean Square          ID  \\\n3378                  NaN               NaN               NaN  USP0000A09   \n3379                  NaN               NaN               NaN  USP0000A0A   \n3380                  NaN               NaN               NaN  USP0000A0C   \n3381                  NaN               NaN               NaN  USP0000A12   \n3382                  NaN               NaN               NaN  USP0000A1H   \n\n     Source Location Source Magnitude Source    Status  \n3378     US              US               US  Reviewed  \n3379     US              US               US  Reviewed  \n3380     US              US               US  Reviewed  \n3381     US              US               US  Reviewed  \n3382     US              US               US  Reviewed  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3378</th>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>8.017</td>\n      <td>124.075</td>\n      <td>Earthquake</td>\n      <td>623.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A09</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3379</th>\n      <td>02/23/1975</td>\n      <td>03:53:36</td>\n      <td>-21.727</td>\n      <td>-71.356</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A0A</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3380</th>\n      <td>02/23/1975</td>\n      <td>07:34:11</td>\n      <td>-10.879</td>\n      <td>166.667</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.5</td>\n      <td>MS</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A0C</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3381</th>\n      <td>02/25/1975</td>\n      <td>05:20:05</td>\n      <td>-7.388</td>\n      <td>149.798</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.5</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A12</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>3382</th>\n      <td>02/26/1975</td>\n      <td>04:48:55</td>\n      <td>85.047</td>\n      <td>97.969</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MS</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A1H</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This does appear to be an issue with data entry: ideally, all entries in the column have the same format.  We can get an idea of how widespread this issue is by checking the length of each entry in the \"Date\" column.","metadata":{}},{"cell_type":"code","source":"date_lengths = earthquakes.Date.str.len()\ndate_lengths.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.328135Z","iopub.execute_input":"2023-03-30T07:20:38.328452Z","iopub.status.idle":"2023-03-30T07:20:38.350279Z","shell.execute_reply.started":"2023-03-30T07:20:38.328422Z","shell.execute_reply":"2023-03-30T07:20:38.348953Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"10    23409\n24        3\nName: Date, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Looks like there are two more rows that has a date in a different format.  Run the code cell below to obtain the indices corresponding to those rows and print the data.","metadata":{}},{"cell_type":"code","source":"indices = np.where([date_lengths == 24])[1]\nprint('Indices with corrupted data:', indices)\nearthquakes.loc[indices]","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.351870Z","iopub.execute_input":"2023-03-30T07:20:38.352953Z","iopub.status.idle":"2023-03-30T07:20:38.384173Z","shell.execute_reply.started":"2023-03-30T07:20:38.352902Z","shell.execute_reply":"2023-03-30T07:20:38.383046Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Indices with corrupted data: [ 3378  7512 20650]\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                           Date                      Time  Latitude  \\\n3378   1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017   \n7512   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n20650  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n\n       Longitude        Type  Depth  Depth Error  Depth Seismic Stations  \\\n3378     124.075  Earthquake  623.0          NaN                     NaN   \n7512     -71.766  Earthquake   33.0          NaN                     NaN   \n20650    142.344  Earthquake   10.1         13.9                   289.0   \n\n       Magnitude Magnitude Type  ...  Magnitude Seismic Stations  \\\n3378         5.6             MB  ...                         NaN   \n7512         5.6             MW  ...                         NaN   \n20650        5.8            MWC  ...                         NaN   \n\n       Azimuthal Gap  Horizontal Distance  Horizontal Error  Root Mean Square  \\\n3378             NaN                  NaN               NaN               NaN   \n7512             NaN                  NaN               NaN              1.30   \n20650           32.3                  NaN               NaN              1.06   \n\n               ID Source Location Source Magnitude Source    Status  \n3378   USP0000A09     US              US               US  Reviewed  \n7512   USP0002E81     US              US              HRV  Reviewed  \n20650  USP000HWQP     US              US             GCMT  Reviewed  \n\n[3 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Type</th>\n      <th>Depth</th>\n      <th>Depth Error</th>\n      <th>Depth Seismic Stations</th>\n      <th>Magnitude</th>\n      <th>Magnitude Type</th>\n      <th>...</th>\n      <th>Magnitude Seismic Stations</th>\n      <th>Azimuthal Gap</th>\n      <th>Horizontal Distance</th>\n      <th>Horizontal Error</th>\n      <th>Root Mean Square</th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Location Source</th>\n      <th>Magnitude Source</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3378</th>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>1975-02-23T02:58:41.000Z</td>\n      <td>8.017</td>\n      <td>124.075</td>\n      <td>Earthquake</td>\n      <td>623.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MB</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>USP0000A09</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>7512</th>\n      <td>1985-04-28T02:53:41.530Z</td>\n      <td>1985-04-28T02:53:41.530Z</td>\n      <td>-32.998</td>\n      <td>-71.766</td>\n      <td>Earthquake</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.6</td>\n      <td>MW</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.30</td>\n      <td>USP0002E81</td>\n      <td>US</td>\n      <td>US</td>\n      <td>HRV</td>\n      <td>Reviewed</td>\n    </tr>\n    <tr>\n      <th>20650</th>\n      <td>2011-03-13T02:23:34.520Z</td>\n      <td>2011-03-13T02:23:34.520Z</td>\n      <td>36.344</td>\n      <td>142.344</td>\n      <td>Earthquake</td>\n      <td>10.1</td>\n      <td>13.9</td>\n      <td>289.0</td>\n      <td>5.8</td>\n      <td>MWC</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>32.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.06</td>\n      <td>USP000HWQP</td>\n      <td>US</td>\n      <td>US</td>\n      <td>GCMT</td>\n      <td>Reviewed</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Given all of this information, it's your turn to create a new column \"date_parsed\" in the `earthquakes` dataset that has correctly parsed dates in it.  \n\n**Note**: When completing this problem, you are allowed to (but are not required to) amend the entries in the \"Date\" and \"Time\" columns.  Do not remove any rows from the dataset.","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here\nearthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\nearthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\nearthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\nearthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")\n\n# Check your answer\nq2.check()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:23:29.639527Z","iopub.execute_input":"2023-03-31T23:23:29.640060Z","iopub.status.idle":"2023-03-31T23:23:29.696666Z","shell.execute_reply.started":"2023-03-31T23:23:29.640014Z","shell.execute_reply":"2023-03-31T23:23:29.695480Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_ConvertToDatetime\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq2.hint()\nq2.solution()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:23:17.888409Z","iopub.execute_input":"2023-03-31T23:23:17.888948Z","iopub.status.idle":"2023-03-31T23:23:17.902577Z","shell.execute_reply.started":"2023-03-31T23:23:17.888901Z","shell.execute_reply":"2023-03-31T23:23:17.901402Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"2_ConvertToDatetime\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Since there are only three rows with a fancy type, you might consider manually editing them. For instance, you can begin by setting `earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"`.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Since there are only three rows with a fancy type, you might consider manually editing them. For instance, you can begin by setting `earthquakes.loc[3378, \"Date\"] = \"02/23/1975\"`."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"questionId\": \"2_ConvertToDatetime\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nearthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\nearthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\nearthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\nearthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nearthquakes.loc[3378, \"Date\"] = \"02/23/1975\"\nearthquakes.loc[7512, \"Date\"] = \"04/28/1985\"\nearthquakes.loc[20650, \"Date\"] = \"03/13/2011\"\nearthquakes['date_parsed'] = pd.to_datetime(earthquakes['Date'], format=\"%m/%d/%Y\")\n\n```"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3) Select the day of the month\n\nCreate a Pandas Series `day_of_month_earthquakes` containing the day of the month from the \"date_parsed\" column.","metadata":{}},{"cell_type":"code","source":"# try to get the day of the month from the date column\nday_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n\n# Check your answer\nq3.check()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:23:55.823105Z","iopub.execute_input":"2023-03-31T23:23:55.824446Z","iopub.status.idle":"2023-03-31T23:23:55.838011Z","shell.execute_reply.started":"2023-03-31T23:23:55.824377Z","shell.execute_reply":"2023-03-31T23:23:55.836638Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3_DayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq3.hint()\nq3.solution()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:23:40.196730Z","iopub.execute_input":"2023-03-31T23:23:40.197265Z","iopub.status.idle":"2023-03-31T23:23:40.211412Z","shell.execute_reply.started":"2023-03-31T23:23:40.197209Z","shell.execute_reply":"2023-03-31T23:23:40.210443Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"questionId\": \"3_DayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Use the `.dt` accessor.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Use the `.dt` accessor."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"questionId\": \"3_DayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\nday_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\nday_of_month_earthquakes = earthquakes['date_parsed'].dt.day\n\n```"},"metadata":{}}]},{"cell_type":"markdown","source":"# 4) Plot the day of the month to check the date parsing\n\nPlot the days of the month from your earthquake dataset.","metadata":{}},{"cell_type":"code","source":"# TODO: Your code here!\n","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.428754Z","iopub.execute_input":"2023-03-30T07:20:38.429095Z","iopub.status.idle":"2023-03-30T07:20:38.437559Z","shell.execute_reply.started":"2023-03-30T07:20:38.429062Z","shell.execute_reply":"2023-03-30T07:20:38.436091Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Does the graph make sense to you?","metadata":{}},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq4.check()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.439126Z","iopub.execute_input":"2023-03-30T07:20:38.439475Z","iopub.status.idle":"2023-03-30T07:20:38.452667Z","shell.execute_reply.started":"2023-03-30T07:20:38.439439Z","shell.execute_reply":"2023-03-30T07:20:38.451815Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 4, \"questionId\": \"4_PlotDayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct: \n\nThe graph should make sense: it shows a relatively even distribution in days of the month,which is what we would expect.","text/markdown":"<span style=\"color:#33cc33\">Correct:</span> \n\nThe graph should make sense: it shows a relatively even distribution in days of the month,which is what we would expect."},"metadata":{}}]},{"cell_type":"code","source":"# Line below will give you a hint\nq4.hint()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:24:04.079160Z","iopub.execute_input":"2023-03-31T23:24:04.079626Z","iopub.status.idle":"2023-03-31T23:24:04.090276Z","shell.execute_reply.started":"2023-03-31T23:24:04.079588Z","shell.execute_reply":"2023-03-31T23:24:04.088830Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 4, \"questionId\": \"4_PlotDayOfMonth\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: \nRemove the missing values, and then use `sns.distplot()` as follows:\n\n```python\n# remove na's\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_earthquakes, kde=False, bins=31)\n```\n","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> \nRemove the missing values, and then use `sns.distplot()` as follows:\n\n```python\n# remove na's\nday_of_month_earthquakes = day_of_month_earthquakes.dropna()\n\n# plot the day of the month\nsns.distplot(day_of_month_earthquakes, kde=False, bins=31)\n```\n\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# (Optional) Bonus Challenge\n\nFor an extra challenge, you'll work with a [Smithsonian dataset](https://www.kaggle.com/smithsonian/volcanic-eruptions) that documents Earth's volcanoes and their eruptive history over the past 10,000 years \n\nRun the next code cell to load the data.","metadata":{}},{"cell_type":"code","source":"volcanos = pd.read_csv(\"../input/volcanic-eruptions/database.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.460508Z","iopub.execute_input":"2023-03-30T07:20:38.460883Z","iopub.status.idle":"2023-03-30T07:20:38.488032Z","shell.execute_reply.started":"2023-03-30T07:20:38.460849Z","shell.execute_reply":"2023-03-30T07:20:38.486792Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Try parsing the column \"Last Known Eruption\" from the `volcanos` dataframe. This column contains a mixture of text (\"Unknown\") and years both before the common era (BCE, also known as BC) and in the common era (CE, also known as AD).","metadata":{}},{"cell_type":"code","source":"volcanos['Last Known Eruption'].sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T07:20:38.489975Z","iopub.execute_input":"2023-03-30T07:20:38.491022Z","iopub.status.idle":"2023-03-30T07:20:38.501973Z","shell.execute_reply.started":"2023-03-30T07:20:38.490970Z","shell.execute_reply":"2023-03-30T07:20:38.500518Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"764     Unknown\n1069    1996 CE\n34      1855 CE\n489     2016 CE\n9       1302 CE\nName: Last Known Eruption, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# (Optional) More practice\n\nIf you're interested in graphing time series, [check out this tutorial](https://www.kaggle.com/residentmario/time-series-plotting-optional).\n\nYou can also look into passing columns that you know have dates in them  the `parse_dates` argument in `read_csv`. (The documention [is here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).) Do note that this method can be very slow, but depending on your needs it may sometimes be handy to use.\n\n# Keep going\n\nIn the next lesson, learn how to [**work with character encodings**](https://www.kaggle.com/alexisbcook/character-encodings).","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*","metadata":{}}]}